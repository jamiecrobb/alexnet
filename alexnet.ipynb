{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab721c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the transformation to be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Adjust the size as needed\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and create the VOC Detection dataset for 2012\n",
    "train_dataset = torchvision.datasets.VOCDetection(\n",
    "    root='./data',  # Change the root directory as needed\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=2,  # Adjust the batch size as needed\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4518e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, resize_size=(128, 128)):\n",
    "        self.resize_size = resize_size\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "\n",
    "        # Resize images to the specified size\n",
    "        resized_images = [resize(img, self.resize_size, antialias=True) for img in images]\n",
    "\n",
    "        # Stack resized images into a batch\n",
    "        batched_images = torch.stack(resized_images)\n",
    "\n",
    "        return batched_images, labels\n",
    "\n",
    "# Define the transformation to be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and create the VOC Detection dataset for 2012\n",
    "train_dataset = torchvision.datasets.VOCDetection(\n",
    "    root='./data',  # Change the root directory as needed\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the training dataset with custom collate function\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=16,  # Adjust the batch size as needed\n",
    "    shuffle=True,\n",
    "    collate_fn=MyCollate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb528df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba85763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "num = 5\n",
    "\n",
    "def show_batch(batch_images):\n",
    "    # for images, _ in dl:\n",
    "    fig,ax = plt.subplots(figsize=(16,12))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(make_grid(batch_images,nrow=16).permute(1,2,0))\n",
    "        # break\n",
    "\n",
    "for batch_images, _ in islice(train_loader, num):\n",
    "    show_batch(batch_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
